import utils.myQuaternion as myQuaternion
import torch
import time

POS, VEL, ROT, ANG = 0, 1, 2, 3


######################################################################
#
######################################################################
@torch.jit.script
def local(P0, P1, P2, P3):
    """
    input : (pos, vel, rot, ang)
    return : (pos, vel, rot, ang, hei, up)
    """

    # print([a.shape for a in [P0, P1, P2, P3]])
    rot_mat = myQuaternion.q_2_m(P2).clone()
    root_mat_inv = (rot_mat[..., 0:1, :, :]).inverse()

    pos = (P0 - P0[..., 0:1, :]).unsqueeze(-1)
    pos = torch.einsum("...ij,...jk->...ik", root_mat_inv, pos).squeeze(-1)

    vel = P1.unsqueeze(-1)
    vel = torch.einsum("...ij,...jk->...ik", root_mat_inv, vel).squeeze(-1)

    rot = rot_mat
    rot = torch.einsum("...ij,...jk->...ik", root_mat_inv, rot)[..., 0:2, :]

    ang = P3.unsqueeze(-1)
    ang = torch.einsum("...ij,...jk->...ik", root_mat_inv, ang).squeeze(-1)

    hei = P0[..., 0:1, 2:3]

    up = P0[..., 0:1, :].clone().detach() * 0.0
    up[..., 2:3] += 1
    up = up.unsqueeze(-1)
    up = torch.einsum("...ij,...jk->...ik", root_mat_inv, up).squeeze(-1)

    # print("==============================")
    # print(root_mat_inv.shape, pos.shape)
    # print(root_mat_inv.shape, vel.shape)
    # print(root_mat_inv.shape, rot.shape)
    # print(root_mat_inv.shape, ang.shape)
    # print(root_mat_inv.shape, hei.shape)
    # print(root_mat_inv.shape, up.shape)
    # print("==============================")

    return (pos, vel, rot, ang, hei, up)


######################################################################
@torch.jit.script
def to_serial(a0, a1, a2, a3, a4, a5):
    """
    input : {pos, vel, rot, ang, hei, up}
    return :
    """
    # print([a.shape for a in [a0, a1, a2, a3, a4, a5]])
    # print(a4.flatten(-2).shape)
    buffer = torch.concat(
        (
            a0.flatten(-2),
            a1.flatten(-2),
            a2.flatten(-3),
            a3.flatten(-2),
            a4.flatten(-2),
            a5.flatten(-2),
        ),
        -1,
    )
    # print(buffer.shape)
    return buffer


######################################################################
@torch.jit.script
def integrate(P_pos, P_vel, P_rot, P_ang, vel_of_dt, ang_of_dt, dt):
    """
    input : (
        P_pos, P_vel, P_rot, P_ang,
        vel_of_dt, ang_of_dt,
        dt
        )
    return : (y_pos, y_vel, y_rot, y_ang)
    """
    y_vel = (dt * vel_of_dt) + P_vel
    y_ang = (dt * ang_of_dt) + P_ang
    y_pos = (dt * y_vel) + P_pos
    y_rot = myQuaternion.quat_integrate_angular_velocity(y_ang, P_rot, dt)
    return (y_pos, y_vel, y_rot, y_ang)


######################################################################


######################################################################
#
######################################################################
def gather(rank, model, buffer, env):
    """
    ì¶©ë¶„í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ìžˆë„ë¡ DeepMimic [Peng et al. 2018a].
    ëª¨ì…˜ ìº¡ì²˜ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜¨ í•´ë‹¹ ìš´ë™í•™ ì• ë‹ˆë©”ì´ì…˜ì„ ì¶”ì í•˜ê¸° ìœ„í•´
    PD ì»¨íŠ¸ë¡¤ëŸ¬ì— ì˜í•´ êµ¬ë™ë˜ëŠ” ê° ê´€ì ˆì˜ ëª¨í„°ì™€ ë³‘ë ¬ë¡œ 256ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ê´€ì ˆ
    ìºë¦­í„°ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.
    ìµœëŒ€ ì—í”¼ì†Œë“œ ê¸¸ì´ë¥¼ ì´ˆê³¼í•˜ê±°ë‚˜ ìµœì†Œ ì—í”¼ì†Œë“œ ê¸¸ì´ë¥¼ í™•ë³´í•˜ê³  ìºë¦­í„°ì˜ ë¨¸ë¦¬ ë†’ì´ê°€
    ê¸°ì¤€ì—ì„œ 25cm ì´ìƒ ë²—ì–´ë‚  ë•Œë§ˆë‹¤ ê¸°ì¤€ ìƒíƒœ ì´ˆê¸°í™” [Peng et al. 2018a]ëŠ”
    ì‹œë®¬ë ˆì´íŠ¸ëœ ìºë¦­í„°ë¥¼ í‚¤ë„¤ë§ˆí‹± ì• ë‹ˆë©”ì´ì…˜ ë°ì´í„°ë² ì´ìŠ¤ì˜ ë¬´ìž‘ìœ„ ì• ë‹ˆë©”ì´ì…˜ì—ì„œ
    ë¬´ìž‘ìœ„ í¬ì¦ˆë¡œ ìž¬ì„¤ì •í•˜ëŠ” ë° ì‚¬ìš©ë˜ë©°, ì§€ë©´ ê´€í†µì„ í”¼í•˜ê¸° ìœ„í•´ ìˆ˜ì§ ë³´ì •ì´ ì ìš©ë©ë‹ˆë‹¤.
    ìµœëŒ€ ì—í”¼ì†Œë“œ ê¸¸ì´ëŠ” 512ê°œ, ìµœì†Œ ì—í”¼ì†Œë“œ ê¸¸ì´ëŠ” 48ê°œë¥¼ ì‚¬ìš©í•˜ê³ 
    ì• ë‹ˆë©”ì´ì…˜ì— ëŒ€í•œ ì¼ë¶€ ì‚¬ìš©ìž ì œê³µ í™•ë¥  ë¶„í¬ì™€ ê´€ë ¨í•˜ì—¬ ìž¬ì„¤ì •ì„ ì ìš©í•˜ëŠ”
    ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.
    ì—í”¼ì†Œë“œê°€ ì¢…ë£Œë˜ë©´ í™˜ê²½ì˜ ìƒ˜í”Œì´ ëŒ€ê·œëª¨ ìˆœí™˜ ë°ì´í„° ë²„í¼ì—
    ì¶”ê°€ë©ë‹ˆë‹¤(ìžì„¸í•œ ë‚´ìš©ì€ ì„¹ì…˜ 3.5 ì°¸ì¡°).
    ì´ ì„¤ì •ì€ ì´ˆë‹¹ ~5000ê°œ ìƒ˜í”Œì˜ ì†ë„ë¡œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ì‹œë®¬ë ˆì´ì…˜ ì„¤ì •ì— ëŒ€í•œ ìžì„¸í•œ ë‚´ìš©ì€ ì„¹ì…˜ 5.3ì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.
    """

    ADD_NOISE = buffer.get_noise_gain()
    SCALE = buffer.get_action_gain()

    START, END_SIZE = 0, buffer.get_allocated_size()

    #############################################################
    # setting
    #############################################################
    with torch.no_grad():
        model.eval()
        #############################################################
        # Simulator Initialize
        try:
            _S, _K, _T = gather._S, gather._K, gather._T
            fail_count = gather.fail_count
            timestep = gather.timestep
        except:
            _S, _K, _T = env.init(), env.init(), torch.zeros(21)
            fail_count = 0
            timestep = 0
        # Generate Normaldistributed Noise
        noise = torch.normal(0.0, 1.0, (END_SIZE, 21)) * ADD_NOISE
        # RESET load data
        buffer.start(rank)
        # START LOOP
        while START != END_SIZE:
            # Reset if the head position is lower than the standard.
            if timestep == 128:
                _S = env.reset()
                timestep = 0
                fail_count = False
            elif (timestep % 32) == 0:
                if fail_count:
                    _S = env.reset()
                    timestep = 0
                    fail_count = False
            # Converting to Local
            _T = model.policy(to_serial(*local(*_S)).unsqueeze(0))
            # Add noise
            _T = (_T + noise[START]) * SCALE
            # Stack to Circular Buffer
            buffer.insert(_S, _K, _T)
            # Simulator next step
            _S = env.step(_T)
            # count
            START += 1
            timestep += 1
            fail_count |= env.is_fail()
        # End Step Size
        buffer.next()
        gather._S, gather._K, gather._T = _S, _K, _T
        gather.fail_count = fail_count
        gather.timestep = timestep
    ######################################################################
    return


######################################################################
#
######################################################################
def train_world(model, __buffer, L1, L2, optim_world):
    model.train()

    __S, __K, __T = __buffer.get()
    device = __buffer.get_device_type()

    S = (
        __S[POS].clone().detach().transpose(1, 0).to(device),
        __S[VEL].clone().detach().transpose(1, 0).to(device),
        __S[ROT].clone().detach().transpose(1, 0).to(device),
        __S[ANG].clone().detach().transpose(1, 0).to(device),
    )
    T = __T.clone().detach().transpose(1, 0).to(device)
    P = (
        S[POS].clone().detach(),
        S[VEL].clone().detach(),
        S[ROT].clone().detach(),
        S[ANG].clone().detach(),
    )
    P_i = (
        P[POS][0, ...].clone().detach(),
        P[VEL][0, ...].clone().detach(),
        P[ROT][0, ...].clone().detach(),
        P[ANG][0, ...].clone().detach(),
    )

    delta_time = torch.tensor([0.01]).to(device)
    angular_velocity_time = torch.tensor([1]).to(device)

    optim_world.zero_grad()

    # Predict P over a window of ð‘ frames
    for i in range(8):
        # Predict rigid body accelerations
        buffer = model.world(to_serial(*local(*P_i)), T[i])
        local_vel_dt = buffer[..., 0:48].reshape(-1, 16, 3)
        local_ang_dt = buffer[..., 48:96].reshape(-1, 16, 3)

        # Convert accelerations to world space
        root_mat = myQuaternion.q_2_m(P_i[ROT][..., 0:1, :])  # 1, -1, 1, 4
        world_vel_dt = torch.einsum("...ij,...jk->...ik", root_mat, local_vel_dt.unsqueeze(-1)).squeeze(-1)
        world_ang_dt = torch.einsum("...ij,...jk->...ik", root_mat, local_ang_dt.unsqueeze(-1)).squeeze(-1)

        # Integrate rigid body accelerations
        P_i = integrate(*P_i, world_vel_dt, world_ang_dt, delta_time)

        # P_i integrate to P
        P[POS][i] = P_i[POS].clone()
        P[VEL][i] = P_i[VEL].clone()
        P[ROT][i] = P_i[ROT].clone()
        P[ANG][i] = P_i[ANG].clone()

    # Compute losses
    loss_pos = L1(P[POS], S[POS])
    loss_vel = L1(P[VEL], S[VEL])
    loss_rot = myQuaternion.quat_differentiate_angular_velocity(P[ROT], S[ROT], angular_velocity_time).abs().mean()
    loss_ang = L1(P[ANG], S[ANG])

    # Update network parameters
    loss_sum = loss_pos + loss_vel + loss_rot + loss_ang
    loss_sum.backward()
    optim_world.step()

    return "train_world ", float(loss_sum.detach().cpu().numpy())


def train_policy(model, __buffer, L1, L2, optim_policy):
    """
    ì •ì±… Î ë¥¼ í›ˆë ¨í•˜ê¸° ìœ„í•´ ë¨¼ì € ë°ì´í„° ë²„í¼ì—ì„œ ð‘Î  = 32 í”„ë ˆìž„ì˜ ì°½ì„
    ìƒ˜í”Œë§í•˜ì—¬ ì´ˆê¸° ì‹œë®¬ë ˆì´ì…˜ ìƒíƒœ S0ê³¼ ëª©í‘œ ìš´ë™í•™ì  ìƒíƒœ Kë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ê·¸ëŸ° ë‹¤ìŒ ì‹œë®¬ë ˆì´ì…˜ëœ ìƒíƒœì™€ ì´ˆê¸° ëª©í‘œ ìš´ë™í•™ì  ìƒíƒœê°€ ì •ì±…ì— ê³µê¸‰ë˜ì–´
    PD ì˜¤í”„ì…‹ oë¥¼ ì–»ìŠµë‹ˆë‹¤.
    ðœŽ = 0.1ë¡œ ìŠ¤ì¼€ì¼ë§ëœ ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆëŠ” ì˜¤í”„ì…‹ì— ì¶”ê°€ë˜ì–´ ìƒíƒœ ë° ë™ìž‘
    ê¶¤ì  íƒìƒ‰ì„ ìž¥ë ¤í•˜ê³  ê²°ê³¼ ì˜¤í”„ì…‹ o^ëŠ” ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ ë³€í™˜ë˜ê³  ìš´ë™í•™ì 
    ìºë¦­í„° ê´€ì ˆ íšŒì „ k ð‘¡ë¥¼ ê³±í•˜ê¸° ì „ì— ì „ì²´ ìŠ¤ì¼€ì¼ë§ ì¸ìˆ˜ ð›¼ë¡œ ìŠ¤ì¼€ì¼ë§ë©ë‹ˆë‹¤.
    ê·¸ëŸ° ë‹¤ìŒ ìš´ë™í•™ì  ìºë¦­í„° ê´€ì ˆ íšŒì „ ì†ë„ Â¤k ð‘¡ì™€ ìŒì„ ì´ë£¨ì–´ ìµœì¢… PD ëª©í‘œ
    Të¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ì´ëŸ¬í•œ PD ëª©í‘œëŠ” ì˜ˆì¸¡ëœ ì‹œë®¬ë ˆì´ì…˜ ìƒíƒœì™€ í•¨ê»˜ ì„¸ê³„ ëª¨ë¸ì— ìž…ë ¥ë˜ì–´ ë‹¤ìŒ
    ì‹œë®¬ë ˆì´ì…˜ ìƒíƒœë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ì´ í”„ë¡œì„¸ìŠ¤ëŠ” ì˜ˆì¸¡ëœ ìƒíƒœ Pì˜ ì „ì²´ ì°½ì´ ìƒì„±ë  ë•Œê¹Œì§€ ë°˜ë³µë©ë‹ˆë‹¤.
    ì´ ì˜ˆì¸¡ê³¼ ëª©í‘œ ìš´ë™í•™ì  ìƒíƒœ K ê°„ì˜ ì°¨ì´ëŠ” ë¡œì»¬ ê³µê°„ì—ì„œ ê³„ì‚°ë˜ê³  ì†ì‹¤ì€
    ì •ì±…ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
    ìžì„¸í•œ ë‚´ìš©ì€ Algorithm 2ì™€ Fig 3ì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.
    ð‘¤ð‘¢ð‘ëŠ” í›ˆë ¨ ì‹œìž‘ ì‹œ ëª¨ë“  ì†ì‹¤ì—ì„œ ê±°ì˜ ë™ì¼í•œ ê¸°ì—¬ë„ë¥¼ ì œê³µí•˜ë„ë¡ ì„¤ì •ë˜ëŠ”
    ë°˜ë©´ ì •ê·œí™” ê°€ì¤‘ì¹˜ ð‘¤ð‘™ð‘Ÿà¸¡ð‘” ë° ð‘¤ð‘ ð‘Ÿà¸¡ð‘”ì€ ë‘ ìžë¦¿ìˆ˜ë§Œí¼ ë” ìž‘ì€ ê¸°ì—¬ë„ë¥¼
    ë¶€ì—¬í•˜ê³  í° PD ì˜¤í”„ì…‹ì— íŽ˜ë„í‹°ë¥¼ ì£¼ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
    ì´ ì•Œê³ ë¦¬ì¦˜ì€ ë‹¨ì¼ ìƒ˜í”Œì— ëŒ€í•´ ì œì‹œë˜ì§€ë§Œ í›ˆë ¨ì€ ë¯¸ë‹ˆ ë°°ì¹˜ì—ì„œ ìˆ˜í–‰ë©ë‹ˆë‹¤.
    ì´ ì•Œê³ ë¦¬ì¦˜ì€ ë˜í•œ í›ˆë ¨ìž¥ì—ì„œ í›ˆë ¨ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê¸° ìœ„í•´ ìˆ˜í–‰ë˜ëŠ” ì ˆì°¨ì™€
    ì¼ì¹˜í•˜ì§€ë§Œ ì‹¤ì œ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¸ê³„ ëª¨ë¸ì´ ì•„ë‹Œ ë‹¤ìŒ ì‹œë®¬ë ˆì´ì…˜
    ìƒíƒœë¥¼ ì–»ìŠµë‹ˆë‹¤.
    """

    model.train()

    __S, __K, __T = __buffer.get()
    device = __buffer.get_device_type()

    # init
    K = (
        __K[POS].clone().detach().transpose(1, 0).to(device),
        __K[VEL].clone().detach().transpose(1, 0).to(device),
        __K[ROT].clone().detach().transpose(1, 0).to(device),
        __K[ANG].clone().detach().transpose(1, 0).to(device),
    )
    P = (
        __S[POS].clone().detach().transpose(1, 0).to(device),
        __S[VEL].clone().detach().transpose(1, 0).to(device),
        __S[ROT].clone().detach().transpose(1, 0).to(device),
        __S[ANG].clone().detach().transpose(1, 0).to(device),
    )
    P_i = (
        P[POS][0, ...].clone().detach(),
        P[VEL][0, ...].clone().detach(),
        P[ROT][0, ...].clone().detach(),
        P[ANG][0, ...].clone().detach(),
    )
    TT = __T.detach().clone().transpose(1, 0).to(device)

    Noise = torch.normal(0.0, 1.0, TT.shape)
    Noise *= __buffer.get_noise_gain().clone()  # MULTIPLY NOISE GAIN 0.1
    Noise = Noise.to(device)

    SCALE = __buffer.get_action_gain().clone().to(device)  # CONTROL SCALE

    delta_time = torch.tensor([0.01]).to(device)

    optim_policy.zero_grad()

    # Predict P over a window of ð‘ frames
    for i in range(32):
        # Predict PD offset
        OUT = model.policy(to_serial(*local(*P_i)))
        TT[i] = OUT.clone()

        # Add noise to offset
        OUT_hat = OUT + Noise[i]

        # Compute PD target
        """ Papers and implementations are different. """
        OUT_hat *= SCALE

        # Pass through world mod
        buffer = model.world(to_serial(*local(*P_i)), OUT_hat)
        local_vel_dt = buffer[..., 0:48].reshape(-1, 16, 3)
        local_ang_dt = buffer[..., 48:96].reshape(-1, 16, 3)

        # Convert accelerations to world space
        root_mat = myQuaternion.q_2_m(P_i[ROT][..., 0:1, :])
        world_vel_dt = torch.einsum("...ij,...jk->...ik", root_mat, local_vel_dt.unsqueeze(-1)).squeeze(-1)
        world_ang_dt = torch.einsum("...ij,...jk->...ik", root_mat, local_ang_dt.unsqueeze(-1)).squeeze(-1)

        # Integrate rigid body accelerations
        P_i = integrate(*P_i, world_vel_dt, world_ang_dt, delta_time)

        # P_i integrate to P
        P[POS][i] = P_i[POS].clone()
        P[VEL][i] = P_i[VEL].clone()
        P[ROT][i] = P_i[ROT].clone()
        P[ANG][i] = P_i[ANG].clone()

    # Compute Local Spaces
    P_loss, K_loss = local(*P), local(*K)

    # Compute losses
    loss_pos = L1(P_loss[0], K_loss[0])
    loss_vel = L1(P_loss[1], K_loss[1])
    loss_rot = L1(P_loss[2], K_loss[2])
    loss_ang = L1(P_loss[3], K_loss[3])
    loss_hei = L1(P_loss[4], K_loss[4])
    loss_up = L1(P_loss[5], K_loss[5])
    loss_lreg = (TT**2).mean().sqrt()
    loss_sreg = TT.abs().mean()

    # Update network parameters
    loss_sum = loss_pos + loss_vel + loss_rot + loss_ang + loss_hei + loss_up + loss_lreg + loss_sreg
    loss_sum.backward()
    optim_policy.step()
    return "train_policy", float(loss_sum.cpu().detach().numpy())


if "__main__" == __name__:
    from pyquaternion import Quaternion

    rot_quat = Quaternion(w=1, x=0, y=0, z=0) * Quaternion(w=0, x=1, y=0, z=0)
    rot_mat = rot_quat.rotation_matrix

    rot_quat = torch.from_numpy(rot_quat.elements).to(torch.float32)
    rot_mat = torch.from_numpy(rot_mat).to(torch.float32)

    local = local(
        torch.tensor([[0.0, 2.0, 2.0], [0.0, 3.0, 1.0]]).reshape(-1, 3),
        torch.tensor([[0.0, 1.0, 0.0], [0.0, 1.0, 0.0]]).reshape(-1, 3),
        torch.tensor([[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]]).reshape(-1, 4),
        torch.tensor([[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]).reshape(-1, 3),
    )

    assert torch.all(local[0] == torch.tensor([[0.0, 0.0, 0.0], [0.0, 1.0, -1.0]]))
    assert torch.all(local[1] == torch.tensor([[0.0, 1.0, 0.0], [0.0, 1.0, 0.0]]))
    assert torch.all(local[2] == torch.tensor([[[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]], [[1.0, 0.0, 0.0], [0.0, -1.0, 0.0]]]))
    assert torch.all(local[3] == torch.tensor([[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]))
    assert torch.all(local[4] == torch.tensor([[2.0]]))
    assert torch.all(local[5] == torch.tensor([[0.0, 0.0, 1.0]]))

    integram = integrate(
        torch.tensor([0.0, 1.0, 0.0]),
        torch.tensor([1.0, 0.0, 0.0]),
        torch.tensor([1.0, 0.0, 0.0, 0.0]),
        torch.tensor([torch.pi, 0.0, 0.0]),
        torch.tensor([0.0, 0.0, 0.0]),
        torch.tensor([0.0, 0.0, 0.0]),
        torch.tensor([1]),
    )

    assert torch.all(integram[0] == torch.tensor([1.0, 1.0, 0.0]))
    assert torch.all(integram[1] == torch.tensor([1.0, 0.0, 0.0]))
    assert torch.all(torch.round(integram[2], decimals=3) == torch.tensor([0.0, 1.0, 0.0, 0.0]))
    assert torch.all(integram[3] == torch.tensor([torch.pi, 0.0, 0.0]))
